\section{Related Work}
\label{sec:relwork}

This section presents the selected related work from the literature. We group the relevant studies based on their methods, namely, information retrieval, automated classification, knowledge organization, and feature extraction.

%There are several studies that focus on automating trace link recovery that implement various techniques. The common objective among the studies is to find relation between software artifacts, by performing diverse methods with various input and output types.

\paragraph{Information Retrieval} Transforming the trace link discovery problem into an information retrieval problem is a popular approach. \fba{Cite multiple traceability work that use IR here}. \fba{No need to explain IR, I comment those parts out.} %One of the popular approaches is to view trace link recovery as an information retrieval(IR) problem. Since the objective of IR, which is to find relevant documents in a document collection given a user query, is analogous to finding related software artifacts for a given requirement, it is very natural to approach the trace link recovery challenge as an information retrieval problem. More detailed information about IR can be found in~\cite{IR}. Two of the widely adopted IR methods are vector-space model and probabilistic network model.
% \textbf{Vector-space model}
% Hayes \etal{} apply the vector-space model (VSM) where each software artifact is represented by vectors and trace links are established among the artifacts that have the most similar vectors~\cite{hayes-2003}. The authors apply three versions of the VSM: \emph{i.} vanilla version, \emph{ii.} a version incorporating the technical terms, and \emph{iii.} a version using a thesaurus for semantic association.
% In vector-space model (VSM) method, each software artifact is represented by vectors. Thereby, the task of trace link recovery evolves into identifying vectors that are similar. Hayes \etal{}()~\cite{hayes-2003} experimented with the vector-space model by examining three different version of it, a vanilla version, a version that incorporates technical terms and a version that uses a thesaurus for semantic association. They evaluated their methods on an open source NASA project, containing high level requirements with lower level requirement specifications. Provided in their evaluation, VSM almost always outperforms keyword-based methods and manual tracing in recall metric, but sometimes fails to do so in precision. They pointed out that even in the cases where VSM fails to outperform human analyst, it does perform faster. 
In a study conducted on five software artifact repositories, Capobianco \etal{} demonstrate that focusing on the nouns of software artifacts could improve the accuracy of IR-based methods~\cite{capobianco-2013}.
In a different study, Bonner \etal{} ~\cite{bonner-2023} develop tool that uses the vector-space model to identify trace links between requirements and model-based designs. They  integrate their tool into the Siemens toolchain for Application Lifecycle Management(ALM).
Cleland-Huang \etal{} ~\cite{cleland-huang-2007} develop a tool, utilizing a probabilistic-network(PN) based model which has a confidence score calculated to represent the relations between artifacts. The model is used to produce a list of candidate traces, sorted by confidence scores that represent the confidence in the validity of each link. A human analyst is expected to accept the correct candidates and discard the false positives. Further, best practices for implementing automated traceability are discussed, pointing out the importance of having a traceability strategy and addressing challenges like terminology differences, etc.

A limitation of these methods is that list of possible trace links they produce is not exact and further human effort is required to filter the candidates.

\paragraph{Automated Classification}

Another approach is to view trace link recovery as a binary classification problem where the aim is to classify each possible trace link as valid or not. In a study, Mills examines the performance of various machine learning algorithms on the task of trace link classification. ~\cite{mills-2017} As a result of the experiments he conducts on multiple datasets that contain different artifact types, he indicates that to achieve a fully automated traceability, minimizing False Positive Rate(FPR) is essential and evaluates the classifiers based on their FPR. The results show that Random Forests is the most suitable classifier for this task.
In another study, van Oosten \etal{} ~\cite{VANOOSTEN2023107226} develop a tool that leverages ML classifiers, called LCDTrace. It performs trace link recovery from MDD(Model Driven Development) models to JIRA issues.

\paragraph{Knowledge Organization}

Knowledge organization allows the relating, labeling, and grouping of similar concepts so that their relationship can be traced. Ontology and Taxonomy structures are used to organize and categorize knowledge.
% Ontologies represent each concept as nodes and their relations as edges in a graph.
In their study, Li and Cleland-Huang present a method to incorporate general and domain-specific ontologies into the tracing process. They extract phrases from software artifacts and compute similarity "if a phrase found in the source artifact can be matched via concepts in the ontology to a different phrase in a target
artifact"~\cite{Ontology}.

On the other hand, taxonomies have predefined categories that group concepts with similar contexts. In the domain of traceability, the objective becomes labeling the source and target artifacts with nodes from a taxonomy and associating the artifacts with similar labels. ~\cite{Taxonomy}. In the labeling process, Abdeen ~\cite{abdeen-2023} creates a vector of concepts for both artifacts and taxonomy nodes using Wikipedia Indices and produced a list of recommended taxonomy labels for each artifact using vector similarity.

% \subsection{Spreading Activation}
In a similar manner, semantic relation graphs are also used for relating concepts. Schlutter \etal{} ~\cite{Spreading-Activation} develops a trace link recovery approach that uses semantic relation graphs and the spreading activation method. They employ an NLP pipeline to extract information from requirement specifications, created a semantic relation graph, and used spreading activation to search for relations from requirements to target artifacts.

\paragraph{Feature Extraction}
In addition to automated trace link recovery studies, Gallego \etal{} ~\cite{Marf2023TransFeatExAN} develop a tool that uses a fairly similar NLP feature extraction pipeline to ours. Their tool identifies and extracts potential features for mobile applications, using application-related text documents such as descriptions, changelogs, and user reviews. They implement a custom NLP pipeline, utilizing Natural Language Processing(NLP) techniques like POS tagging and dependency parsing, to extract noun phrases that can potentially be mobile application features.\\

These studies have integrated relatively more modern technologies such as information retrieval, machine learning, knowledge organization, and NLP to automate trace link recovery and encouraged the researchers to implement various approaches to minimize the effort and maximize the quality of requirement traceability.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: