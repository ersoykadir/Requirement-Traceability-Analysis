\section{Related Work}
\label{sec:relwork}

This section presents the selected related work from the literature. We group the relevant studies based on their methods, namely, traceability visualization, information retrieval, automated classification, knowledge organization, and feature extraction.

%There are several studies that focus on automating trace link recovery that implement various techniques. The common objective among the studies is to find relation between software artifacts, by performing diverse methods with various input and output types.
\paragraph{Traceability Visualization} 
In a study, Madaki \etal{}~\cite{madaki-2022} introduce a visual framework and tool named VizTraceArtefacts, which utilizes a node-link diagram where traceability information is represented by color-coded symbols.
Beier \etal{}~\cite{beier-2017} develop a prototype visualization tool "Ariadne's Eye", which has an interactive design that utilizes vertical and balloon tree layouts. In addition to node-link diagram approaches, Merten \etal{}~\cite{merten-2011} study the applicability of NetMap and Sunburst diagrams for visualizing traceability information of requirements. Similarly, Chen \etal{}~\cite{chen-2012} propose a global framework of traces between source code and documentation which combines Treemap and hierarchical tree visualization techniques. Moreover, Rodrigues \etal{}~\cite{rodrigues-2016} propose the MultiVisioTrace tool, which provides a selection between sunburst, graph, tree, and matrix views to select the most appropriate visualization method for a given traceability context. 

Although many approaches are taken for visualizing traceability information and software artifacts, Li and Maalej~\cite{li-2012} present the comparison of different visualization techniques and identify traceability graph as the most suitable approach to support management tasks. 

\paragraph{Information Retrieval} Utilizing Information Retrieval methods for trace link recovery is a popular approach.
Capobianco \etal{}~\cite{capobianco-2013} demonstrate that focusing on the nouns of software artifacts could improve the accuracy of IR-based methods in their study, which was conducted on five software artifact repositories.
Bonner \etal{}~\cite{bonner-2023} develop a tool using the vector-space model to identify trace links between requirements and model-based designs. They integrate their tool into the Siemens toolchain for Application Lifecycle Management (ALM).
Al-Msie'Deen \etal{}~\cite{deen-2023} develop the tool named YamenTrace, which combines Latent Semantic Indexing (LSI) and Formal Concept Analysis (FCA) methods to identify traceability links. LSI is an IR technique that operates on similarities of documents to generate indicators, while FCA enables clustering and extraction of ordered concepts from datasets that have attribute-based objects. 
Marcus \etal{}~\cite{marcus-2003} presents latent semantic analysis to extract the semantics of the documentation and the source code. A vector-space model is created for each artifact, and traceability links are captured using similarity techniques on the model.
Lucia \etal{}~\cite{fasano-2005} introduce a traceability recovery tool integrated within the ADAMS system, ADAMS Re-Trace. The tool utilizes the Latent Semantic Indexing method and they demonstrate the effectiveness of it in a case study involving seven student projects.
Cleland-Huang \etal{}~\cite{cleland-huang-2007} develop a tool, utilizing a probabilistic-network (PN) based model which has a confidence score. The model is used to produce a list of candidate traces, sorted by confidence scores. A human analyst is required to discard the false positives. Hayes \etal{}~\cite{hayes-2005} present a tool named RETRO, which utilizes the TF-IDF algorithm with relevance feedback to trace requirement specifications to defect reports. They experiment with NASA scientific instrument dataset and demonstrate a recall rate of around 85\% and precision rate of around 69\%.

A limitation of these methods is that the list of possible trace links they produce is not exact and further human effort is required to filter the candidates.

\paragraph{Automated Classification} Another approach is to view trace link recovery as a binary classification problem. Mills~\cite{mills-2017} examines the performance of various machine learning algorithms for trace link classification. The results show that Random Forests is the most suitable classifier for this task.

LCDTrace, a tool developed by van Oosten \etal{}~\cite{VANOOSTEN2023107226}, leverages ML classifiers. It performs trace link recovery from MDD(Model Driven Development) models to JIRA issues.
Cleland-Huang \etal{}~\cite{jane-2012} approach the traceability link recovery problem with a method that combines machine learning methods and structural analysis. They train a tracing algorithm with various open-source software projects to provide automated trace-link recovery for supporting software management.
In another study, Cleland-Huang \etal{}~\cite{cleland-2010} present two Machine-learning methods, one requires manually created traceability matrices and the other employs web-mining techniques. These methods improve the quality of traces identified between requirement specifications and regulatory codes in their study.
Mills \etal{}~\cite{mills-2018} propose an approach they named TRAIL, which also utilizes previously captured knowledge about traceability to train a classifier. However, the classifier is then used to identify new traceability links and update the existing ones, therefore addressing the challenge of maintaining updated trace information.

\paragraph{Knowledge Organization} To utilize knowledge organization techniques, Li and Cleland-Huang~\cite{Ontology} present a method to incorporate general and domain-specific ontologies into the tracing process. They extract phrases from software artifacts and compute similarity "if a phrase found in the source artifact can be matched via concepts in the ontology to a different phrase in a target
artifact". 
In the domain of traceability, the objective becomes labeling the source and target artifacts with nodes from a taxonomy and associating the artifacts with similar labels~\cite{Taxonomy}. In the labeling process, Abdeen~\cite{abdeen-2023} creates a vector of concepts for both artifacts and taxonomy nodes using Wikipedia Indices and produced a list of recommended taxonomy labels for each artifact using vector similarity.

 Schlutter \etal{}~\cite{Spreading-Activation} develop a trace link recovery approach that uses semantic relation graphs and the spreading activation method. They employ an NLP pipeline to extract information from requirement specifications, create a semantic relation graph, and use spreading activation to search traces from requirements to target artifacts.

\paragraph{Feature Extraction}
In addition to automated trace link recovery studies, Gallego \etal{}~\cite{Marf2023TransFeatExAN} develop a tool that identifies and extracts potential features for mobile applications, using application-related text documents such as descriptions, changelogs, and user reviews. They implement a custom NLP pipeline, utilizing POS tagging and dependency parsing techniques, to extract noun phrases. In another study, Zisman \etal{}~\cite{zisman-2003} use heuristic rules that match syntactically related terms to capture the traces between requirement specifications and object models automatically. These rules create various traceability links when matches are found. In another study, Von Knethen \etal{}~\cite{knethen-2003} utilize a conceptual trace model that provides semi-automatic trace link recovery and consists of a traceability technique and a supporting tool environment. Their technique provides guidance on what traces should be recorded to support
later impact analyses, and they utilize the tool environment for applicability.\\

These studies have integrated relatively more modern technologies to minimize the effort and maximize the quality of requirement traceability.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: