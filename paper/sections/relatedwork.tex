\section{Related Work}
\label{sec:relwork}

This section presents the selected related work from the literature. We group the relevant studies based on their methods, namely, information retrieval, automated classification, knowledge organization, and feature extraction.

%There are several studies that focus on automating trace link recovery that implement various techniques. The common objective among the studies is to find relation between software artifacts, by performing diverse methods with various input and output types.

\paragraph{Information Retrieval} Transforming the trace link discovery problem into an information retrieval problem is a popular approach. %One of the popular approaches is to view trace link recovery as an information retrieval(IR) problem. Since the objective of IR, which is to find relevant documents in a document collection given a user query, is analogous to finding related software artifacts for a given requirement, it is very natural to approach the trace link recovery challenge as an information retrieval problem. More detailed information about IR can be found in~\cite{IR}. Two of the widely adopted IR methods are vector-space model and probabilistic network model.
% \textbf{Vector-space model}
% Hayes \etal{} apply the vector-space model (VSM) where each software artifact is represented by vectors and trace links are established among the artifacts that have the most similar vectors~\cite{hayes-2003}. The authors apply three versions of the VSM: \emph{i.} vanilla version, \emph{ii.} a version incorporating the technical terms, and \emph{iii.} a version using a thesaurus for semantic association.
% In vector-space model (VSM) method, each software artifact is represented by vectors. Thereby, the task of trace link recovery evolves into identifying vectors that are similar. Hayes \etal{}()~\cite{hayes-2003} experimented with the vector-space model by examining three different version of it, a vanilla version, a version that incorporates technical terms and a version that uses a thesaurus for semantic association. They evaluated their methods on an open source NASA project, containing high level requirements with lower level requirement specifications. Provided in their evaluation, VSM almost always outperforms keyword-based methods and manual tracing in recall metric, but sometimes fails to do so in precision. They pointed out that even in the cases where VSM fails to outperform human analyst, it does perform faster.
Capobianco \etal{}~\cite{capobianco-2013} demonstrate that focusing on the nouns of software artifacts could improve the accuracy of IR-based methods in their study conducted on five software artifact repositories.
Bonner \etal{}~\cite{bonner-2023} develop a tool using the vector-space model to identify trace links between requirements and model-based designs. They  integrate their tool into the Siemens toolchain for Application Lifecycle Management (ALM).
Al-Msie'Deen \etal{}~\cite{deen-2023} develop the tool named YamenTrace, which combines Latent Semantic Indexing (LSI) and Formal Concept Analysis (FCA) methods and identify traceability links between requirements and software artifacts. LSI is an IR technique that operates on similarities of documents to generate indicators, while FCA enables clustering and extraction of ordered concepts from datasets that have attribute-based objects. 
Marcus \etal{}~\cite{marcus-2003} have a similar approach to the automated-trace linking problem by using latent semantic analysis to extract the semantics of the documentation and the source code. A vector-space model is created for each artifact, and traceability links are captured using similarity techniques on the model.
Lucia \etal{}~\cite{fasano-2005} introduce a traceability recovery tool integrated within the ADAMS system, ADAMS Re-Trace. The tool utilizes the Latent Semantic Indexing method and they demonstrate the effectiveness of it in a case study involving seven student projects.
Cleland-Huang \etal{}~\cite{cleland-huang-2007} develop a tool, utilizing a probabilistic-network (PN) based model which has a confidence score calculated to represent the relations between artifacts. The model is used to produce a list of candidate traces, sorted by confidence scores that represent the confidence in the validity of each link. A human analyst is expected to accept the correct candidates and discard the false positives. %Further, best practices for implementing automated traceability are discussed, pointing out the importance of having a traceability strategy and addressing challenges like terminology differences, etc.
Hayes \etal{}~\cite{hayes-2005} present a tool named RETRO, which utilizes the TF-IDF algorithm with relevance feedback to trace requirement specifications to defect reports. They experiment with NASA scientific instrument dataset and demonstrate a recall rate of around 85\% and precision rate of around 69\%.


A limitation of these methods is that the list of possible trace links they produce is not exact and further human effort is required to filter the candidates.

\paragraph{Automated Classification} Another approach is to view trace link recovery as a binary classification problem where the aim is to classify each possible trace link as valid or not. Mills~\cite{mills-2017} examines the performance of various machine learning algorithms on the task of trace link classification. As a result of the experiments he conducts on multiple datasets that contain different artifact types, he indicates that to achieve fully automated traceability, minimizing False Positive Rate (FPR) is essential. The results show that Random Forests is the most suitable classifier for this task.
LCDTrace, a tool developed by van Oosten \etal{}~\cite{VANOOSTEN2023107226}, leverages ML classifiers. It performs trace link recovery from MDD(Model Driven Development) models to JIRA issues.
Kato \etal{}~\cite{kato-2013} propose a semi-automatic method for traceability link recovery between requirement specifications and the source code, specifically for software products larger in scale. In order to address differences in representation between requirements and code elements, they have utilized configuration management log as an intermediary. This classification of requirements and source code elements as common or specific to the products aided in refining the links, resulting in valid traceability links with a recall rate of 76.2\% and a precision rate of 94.1\%. 
Cleland-Huang \etal{}~\cite{jane-2012} approach the traceability link recovery problem with a method that combines machine learning methods and structural analysis. They train a tracing algorithm with various open-source software projects and experimented with the Apache Hadoop framework to test the capability of automated trace-link recovery for supporting software management.
In another study, Cleland-Huang \etal{}~\cite{cleland-2010} present two Machine-learning methods, one requires manually created traceability matrices and the other employs web-mining techniques. These methods improve the quality of traces identified between requirement specifications and regulatory codes in their study.
Mills \etal{}~\cite{mills-2018} propose an approach they named TRAIL, which also utilizes previously captured knowledge about traceability to train a classifier. However, the classifier is then used to identify new traceability links and update the existing ones, therefore addressing the challenge of maintaining updated trace information during system maintenance and evolution.

\paragraph{Knowledge Organization} Knowledge organization allows the relating, labeling, and grouping of similar concepts so that their relationship can be traced. Ontology and Taxonomy structures are used to organize and categorize knowledge.
% Ontologies represent each concept as nodes and their relations as edges in a graph.
Li and Cleland-Huang~\cite{Ontology} present a method to incorporate general and domain-specific ontologies into the tracing process. They extract phrases from software artifacts and compute similarity "if a phrase found in the source artifact can be matched via concepts in the ontology to a different phrase in a target
artifact".

Taxonomies have predefined categories that group concepts with similar contexts. In the domain of traceability, the objective becomes labeling the source and target artifacts with nodes from a taxonomy and associating the artifacts with similar labels~\cite{Taxonomy}. In the labeling process, Abdeen~\cite{abdeen-2023} creates a vector of concepts for both artifacts and taxonomy nodes using Wikipedia Indices and produced a list of recommended taxonomy labels for each artifact using vector similarity.

% \subsection{Spreading Activation}
Semantic relation graphs are also used for relating concepts. Schlutter \etal{}~\cite{Spreading-Activation} develop a trace link recovery approach that uses semantic relation graphs and the spreading activation method. They employ a natural language processing pipeline to extract information from requirement specifications, create a semantic relation graph, and use spreading activation to search for relations from requirements to target artifacts.

\paragraph{Feature Extraction}
In addition to automated trace link recovery studies, Gallego \etal{}~\cite{Marf2023TransFeatExAN} develop a tool that uses a fairly similar NLP feature extraction pipeline to ours. Their tool identifies and extracts potential features for mobile applications, using application-related text documents such as descriptions, changelogs, and user reviews. They implement a custom NLP pipeline, utilizing Natural Language Processing(NLP) techniques like POS tagging and dependency parsing, to extract noun phrases that can potentially be mobile application features. In another study, Zisman \etal{}~\cite{zisman-2003} use heuristic rules that match syntactically related terms to capture the relations between requirement specifications and object models automatically. These rules create various traceability links when matches are found. In another approach, Von Knethen \etal{}~\cite{knethen-2003} utilize a conceptual trace model that supports changes in the software systems. Their approach provides semi-automatic trace link recovery and consists of a traceability technique and a supporting tool environment that integrates two different tools named RequisitePro and Rhapsody. Furthermore, their technique provides guidance on what traces should be recorded to support
later impact analyses, and the use of existing tools for their technique to be applied.\\

These studies have integrated relatively more modern technologies such as information retrieval, machine learning, knowledge organization, and NLP to automate trace link recovery and encouraged the researchers to implement various approaches to minimize the effort and maximize the quality of requirement traceability.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: