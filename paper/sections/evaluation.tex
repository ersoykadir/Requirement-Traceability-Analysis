\section{Evaluation}
\label{sec:eval}

% \begin{itemize}
%     \item Ground truth
%     \item Experiment setup
%     \item Results
%     \item Evaluation of results
% \end{itemize}

This section describes how we evaluated our approach, which focuses on the accuracy of the method utilized in extracting the trace links, namely keyword extraction, TF-IDF vectors and word vectors.

For this purpose, we selected a set of requirements and thir associated software development artifactsto serve as a ground truth. 
The trace links were manually traced  by our team. 
\todo{Have we put the selected requirements and traces somewhere? If not let's put it in our repo. }

The performance of our approach is evaluated using the recall and precision metrics, which inform us about the  percentage of the  traces that were successfully recovered and  the percentage of the traces that are correctly recovered using the following formulas:


$Recall = \dfrac{True Positives}{True Positives + False Negatives}$


$Precision = \dfrac{True Positives}{True Positives + False Positives}$


%In the experiment, true positives indicate the trace links that are identified by the method. 
%False negatives indicate the trace links that are not identified(missed), and false positives indicate the identified trace %links that are incorrect. 
Table~\ref{tab:keyperf} presents the results of the keyword extraction method and 
  Table~\ref{tab:vecperf} shows the results of the vector based methods.


\begin{table}[htb]
\centering
\caption{\label{tab:keyperf}Performance of the Keyword Extraction Method}
\begin{tabular}{lll}
  \toprule
  Method & Recall & Precision\\
  \midrule

Keyword extraction & {0.865} & 0.212 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htb]
\centering
\caption{\label{tab:vecperf}Performance of the Vector-based Methods}
\begin{tabular}{lllll}
\toprule
  & \multicolumn{2}{c}{Word-vector} &  \multicolumn{2}{c}{Tf-idf vector} \\
  \cmidrule{2-5}
{Sim.Threshold   } & {Rec.} & {Prec.} &  {Rec.} & {Prec.}\\
\midrule
0.05    & 1.0 & 0.043 & 0.839 & 0.121 \\
0.15    & 1.0 & 0.043 & 0.573 & 0.256 \\
0.25    & 1.0 & 0.043 & 0.244 & 0.430 \\
0.35    & 1.0 & 0.043 & 0.095 & 0.392 \\
0.45    & 0.965 & 0.071 & 0.025 & 0.125 \\
0.55    & 0.865 & 0.100 & 0.013 & 0.121 \\
0.65    & 0.294 & 0.300 & 0 & 0 \\
\bottomrule
\end{tabular}
\end{table}

Among these mehtods,  the keyword extraction method yielded the best recall-precision pair.
The performance of the vector-based methods  significantly varies according to the threshold value. 
The recall values  approach 1 with low  threshold values which also yield significantly low precision values.
 This indicates that the desired traces are recovered, but also that,  almost all of the SDAs have been identified as candidate traces. 
 On the other hand, high threshold values result in the  opposite,yielding low recall and higher precision values.
% Notably, the word vector method achieved the highest precision value among the results when the threshold was set to 0.25.

In conclusion, these results indicate that each method its strengths, and selecting the most suitable among them is dependent  on the specific project structure and requirements. \todo{I don't find this convinging argument. What kinds of structured would we prefer which methods for? Like what structure? It may depend more on how the project team documents its work as the traces are captured from the articulation of the team members and their code conventions (variable names, commenting etc.)}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
