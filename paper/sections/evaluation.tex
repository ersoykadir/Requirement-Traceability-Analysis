\section{Evaluation Plan}
\label{sec:eval}

% \begin{itemize}
%     \item Ground truth
%     \item Experiment setup
%     \item Results
%     \item Evaluation of results
% \end{itemize}

In this section, we present the evaluation methods we performed for our tool, focusing on the accuracy of the three implemented methods for identifying trace links: keyword extraction, TF-IDF vector and word vector.

For this purpose, we designed an experiment based on a ground truth set. This set consisted of eight requirement statements and software development artifacts that trace to them. These trace links were captured manually by our team. The ground truth set served as a reference to assess the accuracy of the automated methods.

The evaluation metrics used in this experiment were recall and precision values. Recall value presents the percentage of the real traces that are recovered, while precision presents the percentage of the recovered traces that are correct. These values are calculated using the formulas below:
\\

$Recall = \dfrac{True Positives}{True Positives + False Negatives}$
\\

$Precision = \dfrac{True Positives}{True Positives + False Positives}$
\\

In the experiment, true positives indicate the trace links that are identified by the method. False negatives indicate the trace links that are not identified(missed), and false positives indicate the identified trace links that are incorrect. The results of the keyword extraction method are presented in Table I, while the results of the vector based methods are presented in Table II.


\begin{table}[htb]
\centering
\caption{Performance of the Keyword Extraction Method}
\label{tab:keyperf}
\begin{tabular}{lll}
  \toprule
  Method & Recall & Precision\\
  \midrule

Keyword extraction & {0.865} & 0.212 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htb]
\centering
\caption{Performance of the Vector-based Methods}
\label{tab:vecperf}
\begin{tabular}{lllll}
\toprule
  & \multicolumn{2}{c}{Word-vector} &  \multicolumn{2}{c}{Tf-idf vector} \\
  \cmidrule{2-5}
{Sim.Threshold   } & {Rec.} & {Prec.} &  {Rec.} & {Prec.}\\
\midrule
0.05    & 1.0 & 0.043 & 0.839 & 0.121 \\
0.15    & 1.0 & 0.043 & 0.573 & 0.256 \\
0.25    & 1.0 & 0.043 & 0.244 & 0.430 \\
0.35    & 1.0 & 0.043 & 0.095 & 0.392 \\
0.45    & 0.965 & 0.071 & 0.025 & 0.125 \\
0.55    & 0.865 & 0.100 & 0.013 & 0.121 \\
0.65    & 0.294 & 0.300 & 0 & 0 \\
\bottomrule
\end{tabular}
\end{table}

Among the tested methods, the keyword extraction method yielded the best recall-precision pair. Conversely, the performance of the vector-based methods varied significantly by the defined threshold value. For the vector-based methods, the recall value was observed as close to 1 when the threshold value was relatively low, while the precision value dropped substantially, indicating that all the necessary traces are recovered but also almost all of the SDAs have been identified as candidate traces. On the other hand, setting the threshold value too high caused the opposite effect, resulting in low recall and higher precision values.
% Notably, the word vector method achieved the highest precision value among the results when the threshold was set to 0.25.

In conclusion, these results indicate that each method has strong aspects, and selecting the most suitable method highly depends on the specific project structure and requirements.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End: